{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv8Za_4MGd3K"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "l_MV0izIHKJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne8CVmlxHP1p",
        "outputId": "e2c4c6ed-6961-48be-e04d-22a0a8de2bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30KLP6juGd3O"
      },
      "outputs": [],
      "source": [
        "# train_df = pd.read_csv(\"/content/gdrive/MyDrive/College/Semester5/ML/Project/twitter16/twitter16.csv\")\n",
        "# train_df = train_df[['source_tweet','label']].rename(columns = {'source_tweet':'text', 'label':'label'})\n",
        "\n",
        "train_df = pd.read_csv(\"/content/gdrive/MyDrive/College/Semester5/ML/Project/kaggle/train.csv\")\n",
        "train_df = train_df.dropna()\n",
        "train_df = train_df[['text','label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uOq_YWKkGd3O",
        "outputId": "c3db7d12-1eb0-4a81-8b21-e368f26619e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1\n",
              "1  Ever get the feeling your life circles the rou...      0\n",
              "2  Why the Truth Might Get You Fired October 29, ...      1\n",
              "3  Videos 15 Civilians Killed In Single US Airstr...      1\n",
              "4  Print \\nAn Iranian woman has been sentenced to...      1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "trainDF = train_df\n",
        "trainDF.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-u1YRs2Gd3P",
        "outputId": "a1b04bae-ab3d-4029-ac42-8c46fbfc5119"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18285, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "trainDF.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CVpAzBPGd3P"
      },
      "outputs": [],
      "source": [
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX1cicMYGd3Q",
        "outputId": "e71ba248-8eed-4761-a12b-283e8f15407a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13713,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTzRzHz7Gd3T"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "def preprocess(raw_text):\n",
        "\n",
        "    # keep only words\n",
        "    letters_only_text = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
        "\n",
        "    # convert to lower case and split \n",
        "    words = letters_only_text.lower().split()\n",
        "\n",
        "    # remove stopwords\n",
        "    stopword_set = set(stopwords.words(\"english\"))\n",
        "    meaningful_words = [w for w in words if w not in stopword_set]\n",
        "    \n",
        "    #stemmed words\n",
        "    ps = PorterStemmer()\n",
        "    stemmed_words = [ps.stem(word) for word in meaningful_words]\n",
        "    \n",
        "    #join the cleaned words in a list\n",
        "    cleaned_word_list = \" \".join(stemmed_words)\n",
        "\n",
        "    return cleaned_word_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2l4NG4iIGN1",
        "outputId": "1e6537cb-233f-4ee2-d77d-db2feabcba0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XR8DQ9BEGd3U"
      },
      "outputs": [],
      "source": [
        "df = trainDF\n",
        "df['text'] = df['text'].apply(lambda line : preprocess(line))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/gdrive/MyDrive/College/Semester5/ML/Project/kaggle/processed.csv\")"
      ],
      "metadata": {
        "id": "7eR9Wplmb6k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1BUDgkaGd3U"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def split_dataset_into_words(dataset):\n",
        "    datawords = dataset.apply(lambda x: x.split())\n",
        "    return list(datawords)\n",
        "\n",
        "#  my_list = all_incidents \n",
        "# dictionnary\n",
        "def buffer_stemmisation_keywords(my_list):\n",
        "    my_list = [item for sublist in my_list for item in sublist]\n",
        "    aux = pd.DataFrame(my_list, columns =['word'] )\n",
        "    aux['word_stemmed'] = aux['word'].apply(lambda x : stemmer.stem(x))\n",
        "    aux = aux.groupby('word_stemmed').transform(lambda x: ', '.join(x))\n",
        "    aux['word_stemmed'] = aux['word'].apply(lambda x : stemmer.stem(x.split(',')[0]))\n",
        "    aux.index = aux['word_stemmed']\n",
        "    del aux['word_stemmed']\n",
        "    my_dict = aux.to_dict('dict')['word']\n",
        "    return my_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIvRZYkcGd3U"
      },
      "outputs": [],
      "source": [
        "dictionnary_all_words_unstemmed = buffer_stemmisation_keywords(split_dataset_into_words(df['text']))\n",
        "\n",
        "# Dictionnary de-duplicated\n",
        "for key, value in dictionnary_all_words_unstemmed.items():\n",
        "    new_value = value.replace(\",\", \"\")\n",
        "    new_value = list(set(value.split()))\n",
        "    new_value = list(set(map(lambda each:each.strip(\",\"), new_value)))\n",
        "    dictionnary_all_words_unstemmed[key]=new_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/gdrive/MyDrive/College/Semester5/ML/Project/kaggle/processed2.csv\")"
      ],
      "metadata": {
        "id": "BHvqEwWmc0sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cX5xDwJGd3W"
      },
      "outputs": [],
      "source": [
        "# split the dataset into training and validation datasets \n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['text'], df['label'])\n",
        "\n",
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o55MZxHAGd3W"
      },
      "outputs": [],
      "source": [
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(df['text'])\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQsJzE-0Gd3X"
      },
      "outputs": [],
      "source": [
        "# word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=1900)\n",
        "tfidf_vect.fit(trainDF['text'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
        "\n",
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=1900)\n",
        "tfidf_vect_ngram.fit(trainDF['text'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
        "\n",
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=1900)\n",
        "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PT6Di9JiGd3Z"
      },
      "outputs": [],
      "source": [
        "# load the pre-trained word-embedding vectors \n",
        "embeddings_index = {}\n",
        "for i, line in enumerate(open('/content/gdrive/MyDrive/Amazon/productner/data/glove.6B.100d.txt')):\n",
        "    values = line.split()\n",
        "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
        "\n",
        "# create a tokenizer \n",
        "token = text.Tokenizer()\n",
        "token.fit_on_texts(trainDF['text'])\n",
        "word_index = token.word_index\n",
        "\n",
        "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
        "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
        "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
        "\n",
        "# create token-embedding mapping\n",
        "embedding_matrix = numpy.zeros((len(word_index) + 1, 100))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    \n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return metrics.accuracy_score(predictions, valid_y), metrics.precision_score(predictions, valid_y),metrics.recall_score(predictions, valid_y),metrics.f1_score(predictions, valid_y)"
      ],
      "metadata": {
        "id": "VkCMXjy7JIK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnQmWfKZGd3b",
        "outputId": "7d41d2cd-6c4e-41e0-f29d-75af0e506ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NB, Count Vectors:  (0.8932038834951457, 0.8444444444444444, 0.9047619047619048, 0.8735632183908046)\n",
            "NB, WordLevel TF-IDF:  (0.9029126213592233, 0.8888888888888888, 0.8888888888888888, 0.8888888888888888)\n",
            "NB, N-Gram Vectors:  (0.8737864077669902, 0.9333333333333333, 0.8076923076923077, 0.8659793814432989)\n",
            "NB, CharLevel Vectors:  (0.9223300970873787, 0.9333333333333333, 0.8936170212765957, 0.9130434782608695)\n"
          ]
        }
      ],
      "source": [
        "# Naive Bayes on Count Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
        "print(\"NB, Count Vectors: \", accuracy)\n",
        "\n",
        "# Naive Bayes on Word Level TF IDF Vectors\n",
        "\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"NB, WordLevel TF-IDF: \", accuracy)\n",
        "\n",
        "# Naive Bayes on Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"NB, N-Gram Vectors: \", accuracy)\n",
        "\n",
        "# Naive Bayes on Character Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"NB, CharLevel Vectors: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHPquUriGd3c",
        "outputId": "76150407-9d52-41d8-ebd8-446326c20452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR, Count Vectors:  (0.8932038834951457, 0.8222222222222222, 0.925, 0.8705882352941177)\n",
            "LR, WordLevel TF-IDF:  (0.9029126213592233, 0.8444444444444444, 0.926829268292683, 0.8837209302325582)\n",
            "LR, N-Gram Vectors:  (0.8252427184466019, 0.8888888888888888, 0.7547169811320755, 0.8163265306122449)\n",
            "LR, CharLevel Vectors:  (0.912621359223301, 0.8222222222222222, 0.9736842105263158, 0.891566265060241)\n"
          ]
        }
      ],
      "source": [
        "# Linear Classifier on Count Vectors\n",
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
        "print(\"LR, Count Vectors: \", accuracy)\n",
        "\n",
        "# Linear Classifier on Word Level TF IDF Vectors\n",
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"LR, WordLevel TF-IDF: \", accuracy)\n",
        "\n",
        "# Linear Classifier on Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"LR, N-Gram Vectors: \", accuracy)\n",
        "\n",
        "# Linear Classifier on Character Level TF IDF Vectors\n",
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"LR, CharLevel Vectors: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iQKaAKRGd3d",
        "outputId": "1f21319e-41a5-4409-8b55-ad230b7c189f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM, Count Vectors:  (0.912621359223301, 0.8444444444444444, 0.95, 0.8941176470588236)\n",
            "SVM, WordLevel TF-IDF:  (0.912621359223301, 0.8444444444444444, 0.95, 0.8941176470588236)\n",
            "SVM, N-Gram Vectors:  (0.8155339805825242, 0.9111111111111111, 0.7321428571428571, 0.8118811881188118)\n",
            "SVM, CharLevel Vectors:  (0.9223300970873787, 0.8444444444444444, 0.9743589743589743, 0.9047619047619048)\n"
          ]
        }
      ],
      "source": [
        "# Linear Classifier on Count Vectors\n",
        "accuracy = train_model(svm.SVC(), xtrain_count, train_y, xvalid_count)\n",
        "print(\"SVM, Count Vectors: \", accuracy)\n",
        "\n",
        "# Linear Classifier on Word Level TF IDF Vectors\n",
        "accuracy = train_model(svm.SVC(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"SVM, WordLevel TF-IDF: \", accuracy)\n",
        "\n",
        "# Linear Classifier on Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"SVM, N-Gram Vectors: \", accuracy)\n",
        "\n",
        "# Linear Classifier on Character Level TF IDF Vectors\n",
        "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"SVM, CharLevel Vectors: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRBQ3KEVGd3d"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olGiwp48Gd3d",
        "outputId": "a4f8b4ea-39e1-458f-d5e3-2298556e432b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF, Count Vectors:  (0.9029126213592233, 0.8, 0.972972972972973, 0.8780487804878049)\n",
            "RF, WordLevel TF-IDF:  (0.883495145631068, 0.7777777777777778, 0.9459459459459459, 0.8536585365853658)\n",
            "RF, CharLevel Vectors:  (0.9223300970873787, 0.8444444444444444, 0.9743589743589743, 0.9047619047619048)\n"
          ]
        }
      ],
      "source": [
        "# Linear Classifier on Count Vectors\n",
        "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count)\n",
        "print(\"RF, Count Vectors: \", accuracy)\n",
        "\n",
        "# Linear Classifier on Word Level TF IDF Vectors\n",
        "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"RF, WordLevel TF-IDF: \", accuracy)\n",
        "\n",
        "# # Linear Classifier on Ngram Level TF IDF Vectors\n",
        "# accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "# print(\"RF, N-Gram Vectors: \", accuracy)\n",
        "\n",
        "# Linear Classifier on Character Level TF IDF Vectors\n",
        "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"RF, CharLevel Vectors: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1jtP2G5Gd3e",
        "outputId": "ac416f66-5cea-47d4-bd8c-7ed5367a68b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xgb, Count Vectors:  (0.8155339805825242, 0.7555555555555555, 0.8095238095238095, 0.7816091954022989)\n",
            "Xgb, WordLevel TF-IDF:  (0.8446601941747572, 0.7555555555555555, 0.8717948717948718, 0.8095238095238095)\n",
            "Xgb, CharLevel Vectors:  (0.9029126213592233, 0.8666666666666667, 0.9069767441860465, 0.8863636363636364)\n"
          ]
        }
      ],
      "source": [
        "# Extereme Gradient Boosting on Count Vectors\n",
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\n",
        "print(\"Xgb, Count Vectors: \", accuracy)\n",
        "\n",
        "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\n",
        "print(\"Xgb, WordLevel TF-IDF: \", accuracy)\n",
        "\n",
        "# Extereme Gradient Boosting on Character Level TF IDF Vectors\n",
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\n",
        "print(\"Xgb, CharLevel Vectors: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "zp2gm0SSJt5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NN Baselines"
      ],
      "metadata": {
        "id": "pNaRcy6458CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "\n",
        "    classifier.fit(feature_vector_train, label, epochs=10)\n",
        "\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    pred =[]\n",
        "    for i in predictions:\n",
        "        pred.append([np.round(i[0])])\n",
        "    predictions = pred\n",
        "    return metrics.accuracy_score(predictions, valid_y), metrics.precision_score(predictions, valid_y),metrics.recall_score(predictions, valid_y),metrics.f1_score(predictions, valid_y)"
      ],
      "metadata": {
        "id": "zxtXwa22KqsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd7BDTtIGd3e",
        "outputId": "9a9ba5e1-30f0-4776-fbe1-db5a303316b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1s 9ms/step - loss: 0.6836\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6688\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6520\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6338\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6117\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5858\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5659\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5403\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5124\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4895\n",
            "accuracy:- 0.7864077669902912\n",
            "precision:- 0.7111111111111111\n",
            "recall:- 0.7804878048780488\n",
            "f1 score:- 0.7441860465116279\n"
          ]
        }
      ],
      "source": [
        "def create_cnn():\n",
        "\n",
        "    input_layer = layers.Input((70, ))\n",
        "\n",
        "    embedding_layer = layers.Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], trainable = False)(input_layer)\n",
        "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
        "\n",
        "    pooling_layer = layers.GlobalAveragePooling1D()(conv_layer)\n",
        "\n",
        "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(pooling_layer)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
        "    \n",
        "    return model\n",
        "\n",
        "classifier = create_cnn()\n",
        "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
        "\n",
        "print (\"accuracy:-\", accuracy[0])\n",
        "print (\"precision:-\", accuracy[1])\n",
        "print (\"recall:-\", accuracy[2])\n",
        "print (\"f1 score:-\", accuracy[3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z81WjeyDGd3e",
        "outputId": "aacdcbe8-9964-4160-8840-a7a8274832e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 3s 61ms/step - loss: 0.6711\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.5727\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.3600\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.2347\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.1301\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.0909\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.0418\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0286\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.0162\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0072\n",
            "RNN-LSTM, Word Embeddings (0.883495145631068, 0.8222222222222222, 0.9024390243902439, 0.8604651162790697)\n"
          ]
        }
      ],
      "source": [
        "def create_rnn_lstm():\n",
        "    # Add an Input Layer\n",
        "    input_layer = layers.Input((70, ))\n",
        "\n",
        "    # Add the word embedding Layer\n",
        "    embedding_layer = layers.Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], trainable=True)(input_layer)\n",
        "    # embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    # Add the LSTM Layer\n",
        "    lstm_layer = layers.LSTM(100)(embedding_layer)\n",
        "\n",
        "    # Add the output Layers\n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
        "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
        "\n",
        "    # Compile the model\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
        "    \n",
        "    return model\n",
        "\n",
        "classifier = create_rnn_lstm()\n",
        "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
        "print(\"RNN-LSTM, Word Embeddings\",  accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrC21F1MGd3f",
        "outputId": "60c2355b-a3dd-44fc-df53-e04d278debdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 3s 58ms/step - loss: 0.6824\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.6382\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.5449\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.3823\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.2096\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1032\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0557\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0388\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0200\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0131\n",
            "RNN-GRU, Word Embeddings (0.8737864077669902, 0.8666666666666667, 0.8478260869565217, 0.8571428571428571)\n"
          ]
        }
      ],
      "source": [
        "def create_rnn_gru():\n",
        "    # Add an Input Layer\n",
        "    input_layer = layers.Input((70, ))\n",
        "\n",
        "    # Add the word embedding Layer\n",
        "    embedding_layer = layers.Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], trainable=True)(input_layer)\n",
        "    # embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    # Add the GRU Layer\n",
        "    lstm_layer = layers.GRU(100)(embedding_layer)\n",
        "\n",
        "    # Add the output Layers\n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
        "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
        "\n",
        "    # Compile the model\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
        "    \n",
        "    return model\n",
        "\n",
        "classifier = create_rnn_gru()\n",
        "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
        "print(\"RNN-GRU, Word Embeddings\",  accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26nV2G0XGd3f",
        "outputId": "da53b7ce-6dab-42c4-aea6-ea3a7b2ede29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 5s 102ms/step - loss: 0.6919\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 0.6364\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.5825\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.3950\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.2372\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.1359\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0768\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.0342\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0125\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.0039\n",
            "RNN-Bidirectional, Word Embeddings (0.8932038834951457, 0.8444444444444444, 0.9047619047619048, 0.8735632183908046)\n"
          ]
        }
      ],
      "source": [
        "def create_bidirectional_rnn():\n",
        "    # Add an Input Layer\n",
        "    input_layer = layers.Input((70, ))\n",
        "\n",
        "    # Add the word embedding Layer\n",
        "    embedding_layer = layers.Embedding(len(word_index) + 1, 100, weights=[embedding_matrix], trainable=True)(input_layer)\n",
        "    # embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    # Add the LSTM Layer\n",
        "    lstm_layer = layers.Bidirectional(layers.GRU(100))(embedding_layer)\n",
        "\n",
        "    # Add the output Layers\n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
        "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
        "\n",
        "    # Compile the model\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
        "    \n",
        "    return model\n",
        "\n",
        "classifier = create_bidirectional_rnn()\n",
        "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
        "print(\"RNN-Bidirectional, Word Embeddings\",  accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, Lambda, Concatenate, Conv1D, GlobalMaxPooling1D\n",
        "\n",
        "\n",
        "class RCNN(Model):\n",
        "    def __init__(self,\n",
        "                 maxlen,\n",
        "                 max_features,\n",
        "                 embedding_dims,\n",
        "                 class_num=1,\n",
        "                 last_activation='sigmoid'):\n",
        "        super(RCNN, self).__init__()\n",
        "        self.maxlen = maxlen\n",
        "        self.max_features = max_features\n",
        "        self.embedding_dims = embedding_dims\n",
        "        self.class_num = class_num\n",
        "        self.last_activation = last_activation\n",
        "        self.embedding = Embedding(self.max_features, self.embedding_dims, input_length=self.maxlen, trainable = False)\n",
        "        self.forward_rnn = SimpleRNN(128, return_sequences=True)\n",
        "        self.backward_rnn = SimpleRNN(128, return_sequences=True, go_backwards=True)\n",
        "        self.reverse = Lambda(lambda x: tf.reverse(x, axis=[1]))\n",
        "        self.concatenate = Concatenate(axis=2)\n",
        "        self.conv = Conv1D(64, kernel_size=3, activation='relu')\n",
        "        self.max_pooling = GlobalMaxPooling1D()\n",
        "        self.classifier = Dense(self.class_num, activation=self.last_activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if len(inputs) != 3:\n",
        "            raise ValueError('The length of inputs of RCNN must be 3, but now is %d' % len(inputs))\n",
        "        input_current = inputs[0]\n",
        "        input_left = inputs[1]\n",
        "        input_right = inputs[2]\n",
        "        if len(input_current.get_shape()) != 2 or len(input_left.get_shape()) != 2 or len(input_right.get_shape()) != 2:\n",
        "            raise ValueError('The rank of inputs of RCNN must be (2, 2, 2), but now is (%d, %d, %d)' % (len(input_current.get_shape()), len(input_left.get_shape()), len(input_right.get_shape())))\n",
        "        if input_current.get_shape()[1] != self.maxlen or input_left.get_shape()[1] != self.maxlen or input_right.get_shape()[1] != self.maxlen:\n",
        "            raise ValueError('The maxlen of inputs of RCNN must be (%d, %d, %d), but now is (%d, %d, %d)' % (self.maxlen, self.maxlen, self.maxlen, input_current.get_shape()[1], input_left.get_shape()[1], input_right.get_shape()[1]))\n",
        "        embedding_current = self.embedding(input_current)\n",
        "        embedding_left = self.embedding(input_left)\n",
        "        embedding_right = self.embedding(input_right)\n",
        "        x_left = self.forward_rnn(embedding_left)\n",
        "        x_right = self.backward_rnn(embedding_right)\n",
        "        x_right = self.reverse(x_right)\n",
        "        x = self.concatenate([x_left, embedding_current, x_right])\n",
        "        x = self.conv(x)\n",
        "        x = self.max_pooling(x)\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "Qh_Rf0so-vw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "   \n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Embedding, Dense, Concatenate, Conv1D, Bidirectional, LSTM, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "\n",
        "\n",
        "class RCNNVariant(Model):\n",
        "    \"\"\"Variant of RCNN.\n",
        "        Base on structure of RCNN, we do some improvement:\n",
        "        1. Ignore the shift for left/right context.\n",
        "        2. Use Bidirectional LSTM/GRU to encode context.\n",
        "        3. Use Multi-CNN to represent the semantic vectors.\n",
        "        4. Use ReLU instead of Tanh.\n",
        "        5. Use both AveragePooling and MaxPooling.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 maxlen,\n",
        "                 max_features,\n",
        "                 embedding_dims,\n",
        "                 kernel_sizes=[1, 2, 3, 4, 5],\n",
        "                 class_num=1,\n",
        "                 last_activation='sigmoid'):\n",
        "        super(RCNNVariant, self).__init__()\n",
        "        self.maxlen = maxlen\n",
        "        self.max_features = max_features\n",
        "        self.embedding_dims = embedding_dims\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.class_num = class_num\n",
        "        self.last_activation = last_activation\n",
        "        self.embedding = Embedding(self.max_features, self.embedding_dims, input_length=self.maxlen)\n",
        "        self.bi_rnn = Bidirectional(LSTM(128, return_sequences=True))\n",
        "        self.concatenate = Concatenate()\n",
        "        self.convs = []\n",
        "        for kernel_size in self.kernel_sizes:\n",
        "            conv = Conv1D(128, kernel_size, activation='relu')\n",
        "            self.convs.append(conv)\n",
        "        self.avg_pooling = GlobalAveragePooling1D()\n",
        "        self.max_pooling = GlobalMaxPooling1D()\n",
        "        self.classifier = Dense(self.class_num, activation=self.last_activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if len(inputs.get_shape()) != 2:\n",
        "            raise ValueError('The rank of inputs of TextRNN must be 2, but now is %d' % len(inputs.get_shape()))\n",
        "        if inputs.get_shape()[1] != self.maxlen:\n",
        "            raise ValueError('The maxlen of inputs of TextRNN must be %d, but now is %d' % (self.maxlen, inputs.get_shape()[1]))\n",
        "        embedding = self.embedding(inputs)\n",
        "        x_context = self.bi_rnn(embedding)\n",
        "        x = self.concatenate([embedding, x_context])\n",
        "        convs = []\n",
        "        for i in range(len(self.kernel_sizes)):\n",
        "            conv = self.convs[i](x)\n",
        "            convs.append(conv)\n",
        "        poolings = [self.avg_pooling(conv) for conv in convs] + [self.max_pooling(conv) for conv in convs]\n",
        "        x = self.concatenate(poolings)\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "o3FyL7bYEAHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "max_features = 5000\n",
        "maxlen = 40\n",
        "batch_size = 32\n",
        "embedding_dims = 50\n",
        "\n",
        "\n",
        "print('Loading data...')\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/College/Semester5/ML/Project/twitter15/twitter15.csv\")\n",
        "df = df.rename(columns = {'source_tweet':'message', 'label':'class'})\n",
        "df = df.sample(frac=1)\n",
        "train = df[:int(0.80*df.shape[0])]\n",
        "test = df[int(0.80*df.shape[0]):]\n",
        "print(train.columns)\n",
        "print(test.columns)\n",
        "x_train, y_train, x_test, y_test = train['message'], train['class'], test['message'], test['class']\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)...')\n",
        "# x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "# x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "\n",
        "embeddings_index = {}\n",
        "for i, line in enumerate(open('/content/gdrive/MyDrive/Amazon/productner/data/glove.6B.100d.txt')):\n",
        "    values = line.split()\n",
        "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
        "\n",
        "token = text.Tokenizer()\n",
        "token.fit_on_texts(train['message'])\n",
        "word_index = token.word_index\n",
        "\n",
        "x_train = sequence.pad_sequences(token.texts_to_sequences(x_train), maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(token.texts_to_sequences(x_test), maxlen=maxlen)\n",
        "\n",
        "\n",
        "# print('Prepare input for model...')\n",
        "# x_train_current = x_train\n",
        "# x_train_left = np.hstack([np.expand_dims(x_train[:, 0], axis=1), x_train[:, 0:-1]])\n",
        "# x_train_right = np.hstack([x_train[:, 1:], np.expand_dims(x_train[:, -1], axis=1)])\n",
        "# x_test_current = x_test\n",
        "# x_test_left = np.hstack([np.expand_dims(x_test[:, 0], axis=1), x_test[:, 0:-1]])\n",
        "# x_test_right = np.hstack([x_test[:, 1:], np.expand_dims(x_test[:, -1], axis=1)])\n",
        "# print('x_train_current shape:', x_train_current.shape)\n",
        "# print('x_train_left shape:', x_train_left.shape)\n",
        "# print('x_train_right shape:', x_train_right.shape)\n",
        "# print('x_test_current shape:', x_test_current.shape)\n",
        "# print('x_test_left shape:', x_test_left.shape)\n",
        "# print('x_test_right shape:', x_test_right.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxQCXQcy-xQm",
        "outputId": "76ccdad6-5341-4511-b21a-482246a9f46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Index(['tweetID', 'message', 'class', 'tree'], dtype='object')\n",
            "Index(['tweetID', 'message', 'class', 'tree'], dtype='object')\n",
            "592 train sequences\n",
            "149 test sequences\n",
            "Pad sequences (samples x time)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Prepare input for model...')\n",
        "x_train_current = x_train\n",
        "x_train_left = np.hstack([np.expand_dims(x_train[:, 0], axis=1), x_train[:, 0:-1]])\n",
        "x_train_right = np.hstack([x_train[:, 1:], np.expand_dims(x_train[:, -1], axis=1)])\n",
        "x_test_current = x_test\n",
        "x_test_left = np.hstack([np.expand_dims(x_test[:, 0], axis=1), x_test[:, 0:-1]])\n",
        "x_test_right = np.hstack([x_test[:, 1:], np.expand_dims(x_test[:, -1], axis=1)])\n",
        "print('x_train_current shape:', x_train_current.shape)\n",
        "print('x_train_left shape:', x_train_left.shape)\n",
        "print('x_train_right shape:', x_train_right.shape)\n",
        "print('x_test_current shape:', x_test_current.shape)\n",
        "print('x_test_left shape:', x_test_left.shape)\n",
        "print('x_test_right shape:', x_test_right.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxnkt526BxBg",
        "outputId": "d3052f29-9f01-422e-caf8-b8ce67d5f705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepare input for model...\n",
            "x_train_current shape: (592, 40)\n",
            "x_train_left shape: (592, 40)\n",
            "x_train_right shape: (592, 40)\n",
            "x_test_current shape: (149, 40)\n",
            "x_test_left shape: (149, 40)\n",
            "x_test_right shape: (149, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "print('Build model...')\n",
        "model = RCNN(maxlen, max_features, embedding_dims)\n",
        "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, mode='max')\n",
        "model.fit([x_train_current, x_train_left, x_train_right], y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          callbacks=[early_stopping],\n",
        "          validation_data=([x_test_current, x_test_left, x_test_right], y_test))\n",
        "\n",
        "print('Test...')\n",
        "result = model.predict([x_test_current, x_test_left, x_test_right])\n",
        "\n",
        "\n",
        "\n",
        "# print('Build model...')\n",
        "# model = RCNNVariant(maxlen, max_features, embedding_dims)\n",
        "# model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# print('Train...')\n",
        "# early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, mode='max')\n",
        "# model.fit(x_train, y_train,\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           callbacks=[early_stopping],\n",
        "#           validation_data=(x_test, y_test))\n",
        "\n",
        "# print('Test...')\n",
        "# result = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVIalObaBqlW",
        "outputId": "50e1ad02-5f87-4bb1-ee32-9a616c124516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n",
            "Train...\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 3s 60ms/step - loss: 0.6965 - accuracy: 0.5034 - val_loss: 0.7022 - val_accuracy: 0.4564\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.6438 - accuracy: 0.6047 - val_loss: 1.1105 - val_accuracy: 0.4564\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.6440 - accuracy: 0.6537 - val_loss: 0.7201 - val_accuracy: 0.5906\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.6026 - accuracy: 0.6740 - val_loss: 0.6809 - val_accuracy: 0.5369\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.5635 - accuracy: 0.6892 - val_loss: 0.6417 - val_accuracy: 0.6711\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.5010 - accuracy: 0.7669 - val_loss: 0.7032 - val_accuracy: 0.6309\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.4444 - accuracy: 0.8209 - val_loss: 0.6695 - val_accuracy: 0.6376\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 1s 41ms/step - loss: 0.3909 - accuracy: 0.8361 - val_loss: 0.6633 - val_accuracy: 0.6376\n",
            "Test...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = (result.reshape(1,-1)[0]>0.5).astype(int)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlePzKlJCEvi",
        "outputId": "935dc9f7-9713-40fd-b202-c69b06b61d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ACC\", metrics.accuracy_score(result, y_test))\n",
        "print(\"Prec\", metrics.precision_score(result, y_test))\n",
        "print(\"REC\", metrics.recall_score(result, y_test))\n",
        "print(\"F1\", metrics.f1_score(result, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3zEs08SCI6v",
        "outputId": "468166f6-5215-43e9-a4b4-34b14f08f2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACC 0.6375838926174496\n",
            "Prec 0.7941176470588235\n",
            "REC 0.574468085106383\n",
            "F1 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explaination"
      ],
      "metadata": {
        "id": "F99IgUro5Ox6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxNYhNrvGd3g",
        "outputId": "2e9ebcf7-c578-4275-860f-d1fb931e2eca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.883495145631068"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "\n",
        "vec = TfidfVectorizer(min_df=3, stop_words='english',\n",
        "                      ngram_range=(1, 2))\n",
        "\n",
        "# The dimension of the input documents is reduced to 100, and then a kernel SVM is used to classify the documents.\n",
        "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
        "lsa = make_pipeline(vec, svd)\n",
        "\n",
        "clf = SVC(C=150, gamma=2e-2, probability=True)\n",
        "pipe = make_pipeline(lsa, clf)\n",
        "pipe.fit(train_x.to_numpy(), train_y)\n",
        "pipe.score(valid_x.to_numpy(), valid_y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_x, train_x = valid_x.to_numpy(), train_x.to_numpy()"
      ],
      "metadata": {
        "id": "bx1nE1fKOfTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEGzTP-eGd3h",
        "outputId": "1b57a8b4-f334-4a4f-8c18-195631bdff8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cop arrest dylann roof treat burger king url url\n",
            "------------------------------------ What is the prediction?-------------------------------------------------------\n",
            "0.978 0\n",
            "0.022 1\n"
          ]
        }
      ],
      "source": [
        "def print_prediction(doc):\n",
        "    y_pred = pipe.predict_proba([doc])[0]\n",
        "    for target, prob in zip(np.unique(train_y), y_pred):\n",
        "        print(\"{:.3f} {}\".format(prob, target))\n",
        "\n",
        "doc = valid_x[0]\n",
        "\n",
        "print(valid_x[0])\n",
        "print('------------------------------------ What is the prediction?-------------------------------------------------------')\n",
        "print_prediction(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAg2OlxyGd3h"
      },
      "source": [
        "### TextExplainer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install eli5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KfUeyCCNLvK",
        "outputId": "6d81f65f-7d7e-424f-c924-4225253360dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting eli5\n",
            "  Downloading eli5-0.11.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 61 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 71 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 106 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eli5) (2.11.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.19.5)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (21.2.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eli5) (2.0.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "YKsOweCEGd3h",
        "outputId": "92d3f3dc-dfd0-4163-d74a-a66be3f6dcf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=real\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.951</b>, score <b>2.976</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +3.216\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 96.75%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.240\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 95.80%); opacity: 0.81\" title=\"0.069\">exclus</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 62.54%); opacity: 0.98\" title=\"1.584\">michael</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.84%); opacity: 0.80\" title=\"-0.011\">zahaf</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.740\">bibeau</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.84%); opacity: 0.81\" title=\"0.093\">caught</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.64%); opacity: 0.80\" title=\"-0.002\">dashcam</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.92%); opacity: 0.80\" title=\"-0.025\">model</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.79%); opacity: 0.81\" title=\"0.047\">sold</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.22%); opacity: 0.85\" title=\"-0.461\">url</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.81%); opacity: 0.92\" title=\"1.002\">ottawashoot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.46%); opacity: 0.84\" title=\"-0.332\">url</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ],
      "source": [
        "import eli5\n",
        "from eli5.lime import TextExplainer\n",
        "doc = train_x[2]\n",
        "te = TextExplainer(random_state=42)\n",
        "te.fit(doc, pipe.predict_proba)\n",
        "te.show_prediction(target_names=['fake', 'real'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = train_x[0]\n",
        "te = TextExplainer(random_state=42)\n",
        "te.fit(doc, pipe.predict_proba)\n",
        "te.show_prediction(target_names=['fake', 'real'])"
      ],
      "metadata": {
        "id": "6eUa8zr3RR4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = train_x[1]\n",
        "te = TextExplainer(random_state=42)\n",
        "te.fit(doc, pipe.predict_proba)\n",
        "te.show_prediction(target_names=['fake', 'real'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "NaiH8KdKRUMG",
        "outputId": "7481c5e4-5baf-4445-d5d2-0560628e6a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=fake\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.933</b>, score <b>-2.633</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +2.179\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 93.33%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.454\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.526\">hillaryclinton</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.82%); opacity: 0.84\" title=\"-0.108\">talk</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.09%); opacity: 0.87\" title=\"-0.194\">clinton</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.05%); opacity: 0.80\" title=\"0.013\">gore</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.14%); opacity: 0.85\" title=\"-0.128\">confeder</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.49%); opacity: 0.82\" title=\"-0.058\">campaign</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.43%); opacity: 0.80\" title=\"-0.005\">button</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.57%); opacity: 0.82\" title=\"0.047\">url</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.36%); opacity: 0.92\" title=\"0.310\">url</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = train_x[2]\n",
        "te = TextExplainer(random_state=42)\n",
        "te.fit(doc, pipe.predict_proba)\n",
        "te.show_prediction(target_names=['fake', 'real'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "MG2L1F7BRVKk",
        "outputId": "be6601d5-7fb7-4529-ecec-72fc6a7ae1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=real\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.951</b>, score <b>2.976</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +3.216\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 96.75%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.240\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 95.80%); opacity: 0.81\" title=\"0.069\">exclus</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 62.54%); opacity: 0.98\" title=\"1.584\">michael</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.84%); opacity: 0.80\" title=\"-0.011\">zahaf</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.740\">bibeau</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.84%); opacity: 0.81\" title=\"0.093\">caught</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.64%); opacity: 0.80\" title=\"-0.002\">dashcam</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.92%); opacity: 0.80\" title=\"-0.025\">model</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.79%); opacity: 0.81\" title=\"0.047\">sold</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.22%); opacity: 0.85\" title=\"-0.461\">url</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.81%); opacity: 0.92\" title=\"1.002\">ottawashoot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.46%); opacity: 0.84\" title=\"-0.332\">url</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fj-le5rGSFFp",
        "outputId": "5b78aa6e-bc70-43fc-bb67-684ae9b58a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'exclus michael zahaf bibeau caught dashcam model sold url ottawashoot url'"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = train_x[3]\n",
        "te = TextExplainer(random_state=42)\n",
        "te.fit(doc, pipe.predict_proba)\n",
        "te.show_prediction(target_names=['fake', 'real'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "NoLriD_kRWLt",
        "outputId": "6c9b22a0-bc49-4172-ab04-7b20515ee739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=fake\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.959</b>, score <b>-3.152</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +2.766\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 94.95%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.387\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 88.25%); opacity: 0.83\" title=\"0.160\">leg</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.19%); opacity: 0.81\" title=\"-0.045\">chicken</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.34%); opacity: 0.85\" title=\"-0.220\">fda</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.28%); opacity: 0.82\" title=\"-0.072\">confisc</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.58%); opacity: 0.82\" title=\"-0.099\">sever</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.80%); opacity: 0.81\" title=\"-0.025\">thousand</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.37%); opacity: 0.81\" title=\"0.042\">chicken</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.13%); opacity: 0.96\" title=\"0.758\">kfc</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.31%); opacity: 0.82\" title=\"-0.104\">farm</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.46%); opacity: 0.82\" title=\"0.102\">mutat</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.45%); opacity: 0.80\" title=\"0.002\">worsen</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.922\">url</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = train_x[4]\n",
        "te = TextExplainer(random_state=42)\n",
        "te.fit(doc, pipe.predict_proba)\n",
        "te.show_prediction(target_names=['fake', 'real'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "B5L8V_S5RXoL",
        "outputId": "4d638803-330d-4a45-9bde-07959d6b635a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=fake\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.996</b>, score <b>-5.597</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +4.999\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 95.48%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.598\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 82.11%); opacity: 0.86\" title=\"0.270\">everyon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.91%); opacity: 0.85\" title=\"0.192\">think</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.43%); opacity: 0.96\" title=\"0.692\">starbuck</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.852\">red</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.81%); opacity: 0.92\" title=\"0.517\">cup</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.04%); opacity: 0.82\" title=\"-0.101\">ruin</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.05%); opacity: 0.89\" title=\"0.385\">christma</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.34%); opacity: 0.81\" title=\"0.039\">url</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.29%); opacity: 0.90\" title=\"0.428\">url</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = train_x[5]\n",
        "te = TextExplainer(random_state=42)\n",
        "te.fit(doc, pipe.predict_proba)\n",
        "te.show_prediction(target_names=['fake', 'real'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "UyYdbAzdRYdn",
        "outputId": "3fa2116e-2522-4c92-995c-58cc6412d097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=real\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.944</b>, score <b>2.817</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +2.914\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 98.16%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.097\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 89.34%); opacity: 0.83\" title=\"0.183\">openli</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.99%); opacity: 0.85\" title=\"0.327\">gay</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.78%); opacity: 0.88\" title=\"-0.456\">man</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.42%); opacity: 0.89\" title=\"0.534\">said</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.98%); opacity: 0.84\" title=\"0.217\">partner</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.63%); opacity: 0.82\" title=\"0.130\">met</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 61.71%); opacity: 0.99\" title=\"1.136\">pope</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.209\">franci</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.05%); opacity: 0.93\" title=\"-0.800\">day</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.32%); opacity: 0.91\" title=\"0.642\">kim</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.24%); opacity: 0.94\" title=\"0.831\">davi</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.55%); opacity: 0.81\" title=\"-0.070\">url</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = train_x[7]\n",
        "te = TextExplainer(random_state=42)\n",
        "te.fit(doc, pipe.predict_proba)\n",
        "te.show_prediction(target_names=['fake', 'real'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "13iAcckNRZUz",
        "outputId": "877083d3-509d-4e23-ab66-b292ccfb0700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=fake\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.906</b>, score <b>-2.271</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.880\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 93.33%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.391\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 75.76%); opacity: 0.90\" title=\"-0.374\">month</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.35%); opacity: 0.85\" title=\"-0.200\">ago</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.68%); opacity: 0.84\" title=\"-0.159\">rupert</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.74%); opacity: 0.82\" title=\"-0.080\">murdoch</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.765\">bought</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.67%); opacity: 0.89\" title=\"-0.333\">nation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.66%); opacity: 0.84\" title=\"-0.143\">geograph</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.13%); opacity: 0.83\" title=\"-0.104\">fire</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.15%); opacity: 0.84\" title=\"-0.151\">writer</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.33%); opacity: 0.92\" title=\"0.452\">hit</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.18%); opacity: 0.87\" title=\"-0.261\">stand</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.16%); opacity: 0.93\" title=\"0.503\">url</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "ML Project Baselines.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}